# ü§ñ Gu√≠a de Workflows n8n para EduPlay

Esta gu√≠a te ayudar√° a configurar los workflows de n8n que integran Ollama (IA) con el backend de EduPlay.

## üìã Requisitos Previos

- ‚úÖ Docker corriendo con los 3 servicios: postgres, n8n, ollama
- ‚úÖ Acceso a n8n en http://localhost:5678 (admin/admin123)
- ‚úÖ Modelo phi3 descargado en Ollama
- ‚úÖ Backend de NestJS corriendo en http://localhost:3000

## üîß Verificar que Ollama est√° Listo

```powershell
# Verificar que Ollama est√° corriendo
curl http://localhost:11434/api/tags

# Deber√≠a mostrar el modelo phi3
```

Si phi3 no est√° instalado:
```powershell
docker exec -it ollama ollama pull phi3
```

---

## üéØ Workflow 1: Generaci√≥n de Contenido Educativo

### Endpoint del Webhook
`POST http://localhost:5678/webhook/generate-content`

### Flujo del Workflow

```
[Webhook] ‚Üí [Preparar Prompt] ‚Üí [Ollama] ‚Üí [Parsear JSON] ‚Üí [Responder]
```

### Pasos para Crear en n8n:

1. **Accede a n8n**: http://localhost:5678
   - Usuario: `admin`
   - Contrase√±a: `admin123`

2. **Crear Nuevo Workflow**:
   - Click en "+ Add workflow"
   - Nombre: "Generate Educational Content"

3. **Agregar nodo Webhook**:
   - Busca "Webhook" en el panel izquierdo
   - Arrastra al canvas
   - Configuraci√≥n:
     - **HTTP Method**: POST
     - **Path**: `generate-content`
     - **Response Mode**: "When Last Node Finishes"
     - **Response Data**: "Last Node"

4. **Agregar nodo "Set" (Preparar Prompt)**:
   - Busca "Set" y agr√°stalo
   - Conecta desde Webhook
   - Configuraci√≥n:
     ```json
     {
       "values": {
         "prompt": "=Eres un profesor experto. Genera contenido educativo en espa√±ol para el tema: \"{{ $json.body.topic }}\".\n\nContexto: {{ $json.body.context }}\nCurso: {{ $json.body.courseName }}\n\nGenera EXACTAMENTE {{ $json.body.minItems }} elementos de cada tipo en formato JSON:\n\n{\n  \"flashcards\": [\n    {\"question\": \"¬øPregunta?\", \"answer\": \"Respuesta\"}\n  ],\n  \"cardsMemory\": [\n    {\"card1\": \"Concepto\", \"card2\": \"Definici√≥n\"}\n  ],\n  \"playRelations\": [\n    {\"item1\": \"T√©rmino\", \"item2\": \"Relaci√≥n\"}\n  ],\n  \"quiz\": {\n    \"questions\": [\n      {\n        \"question\": \"¬øPregunta?\",\n        \"optionA\": \"Opci√≥n A\",\n        \"optionB\": \"Opci√≥n B\",\n        \"optionC\": \"Opci√≥n C\",\n        \"optionD\": \"Opci√≥n D\",\n        \"correctOption\": \"A\"\n      }\n    ],\n    \"questionsOpen\": [\n      {\"question\": \"Pregunta abierta\", \"answer\": \"Respuesta esperada\"}\n    ]\n  }\n}\n\nRespuesta SOLO JSON sin texto adicional:"
       }
     }
     ```

5. **Agregar nodo "Ollama"**:
   - Busca "HTTP Request" (usaremos esto para Ollama)
   - Configuraci√≥n:
     - **Method**: POST
     - **URL**: `http://ollama:11434/api/generate`
     - **Body Content Type**: JSON
     - **Body**:
       ```json
       {
         "model": "phi3",
         "prompt": "={{ $json.prompt }}",
         "stream": false,
         "format": "json"
       }
       ```

6. **Agregar nodo "Code" (Parsear Respuesta)**:
   - Busca "Code" y agr√°stalo
   - C√≥digo JavaScript:
     ```javascript
     const ollamaResponse = items[0].json.response;
     
     try {
       // Intentar parsear la respuesta de Ollama
       const generatedContent = JSON.parse(ollamaResponse);
       
       return [{
         json: {
           flashcards: generatedContent.flashcards || [],
           cardsMemory: generatedContent.cardsMemory || [],
           playRelations: generatedContent.playRelations || [],
           quiz: generatedContent.quiz || { questions: [], questionsOpen: [] }
         }
       }];
     } catch (error) {
       // Si falla el parsing, retornar estructura vac√≠a
       return [{
         json: {
           flashcards: [],
           cardsMemory: [],
           playRelations: [],
           quiz: { questions: [], questionsOpen: [] },
           error: "Error parseando respuesta de IA"
         }
       }];
     }
     ```

7. **Activar el Workflow**:
   - Toggle en "Active" (arriba a la derecha)
   - Click en "Save"

---

## üí≠ Workflow 2: An√°lisis de Emoci√≥n

### Endpoint del Webhook
`POST http://localhost:5678/webhook/analyze-emotion`

### Flujo del Workflow

```
[Webhook] ‚Üí [Preparar Prompt] ‚Üí [Ollama] ‚Üí [Parsear Emoci√≥n] ‚Üí [Responder]
```

### Pasos para Crear:

1. **Crear Nuevo Workflow**:
   - Click en "+ Add workflow"
   - Nombre: "Analyze Student Emotion"

2. **Agregar nodo Webhook**:
   - **HTTP Method**: POST
   - **Path**: `analyze-emotion`
   - **Response Mode**: "When Last Node Finishes"

3. **Agregar nodo "Set" (Preparar Prompt)**:
   ```json
   {
     "values": {
       "prompt": "=Analiza el siguiente texto de un estudiante y su calificaci√≥n.\n\nTexto: \"{{ $json.body.text }}\"\nCalificaci√≥n: {{ $json.body.grade }}/10\n\nDetermina:\n1. Emoci√≥n (POSITIVO, NEUTRAL, o NEGATIVO)\n2. Nivel de engagement (0.0 a 1.0)\n3. An√°lisis breve\n\nRespuesta en JSON:\n{\n  \"emotion\": \"POSITIVO|NEUTRAL|NEGATIVO\",\n  \"engagement\": 0.85,\n  \"analysis\": \"Descripci√≥n del an√°lisis\"\n}\n\nRespuesta SOLO JSON:"
     }
   }
   ```

4. **Agregar nodo "HTTP Request" (Ollama)**:
   - **Method**: POST
   - **URL**: `http://ollama:11434/api/generate`
   - **Body**:
     ```json
     {
       "model": "phi3",
       "prompt": "={{ $json.prompt }}",
       "stream": false,
       "format": "json"
     }
     ```

5. **Agregar nodo "Code" (Parsear)**:
   ```javascript
   const ollamaResponse = items[0].json.response;
   
   try {
     const analysis = JSON.parse(ollamaResponse);
     
     // Validar y normalizar valores
     let emotion = analysis.emotion;
     if (!['POSITIVO', 'NEUTRAL', 'NEGATIVO'].includes(emotion)) {
       emotion = 'NEUTRAL';
     }
     
     let engagement = parseFloat(analysis.engagement) || 0.5;
     engagement = Math.max(0, Math.min(1, engagement));
     
     return [{
       json: {
         emotion: emotion,
         engagement: engagement,
         analysis: analysis.analysis || 'An√°lisis completado'
       }
     }];
   } catch (error) {
     // Fallback b√°sico
     return [{
       json: {
         emotion: 'NEUTRAL',
         engagement: 0.5,
         analysis: 'Error en an√°lisis de IA'
       }
     }];
   }
   ```

6. **Activar el Workflow**:
   - Toggle en "Active"
   - Click en "Save"

---

## üß™ Probar los Workflows

### Prueba desde Backend

```powershell
# Probar generaci√≥n de contenido
curl -X POST http://localhost:3000/ai/generate-content/ACTIVITY_ID `
  -H "Content-Type: application/json" `
  -d '{
    "topic": "La Independencia del Per√∫",
    "context": "Periodo hist√≥rico 1821",
    "minItems": 3
  }'

# Probar an√°lisis de emoci√≥n
curl -X POST http://localhost:3000/ai/analyze-emotion `
  -H "Content-Type: application/json" `
  -d '{
    "text": "Me encant√≥ esta clase, aprend√≠ mucho sobre historia",
    "grade": 9
  }'
```

### Prueba Directa en n8n

1. En el workflow, click en el nodo Webhook
2. Click en "Listen for Test Event"
3. Ejecuta el curl desde PowerShell
4. Ver√°s la data llegando en n8n

---

## üîç Troubleshooting

### ‚ùå Error: "Cannot connect to Ollama"
```powershell
# Verificar que Ollama est√° corriendo
docker ps | findstr ollama

# Reiniciar Ollama
docker restart ollama
```

### ‚ùå Error: "Model phi3 not found"
```powershell
# Descargar modelo
docker exec -it ollama ollama pull phi3

# Verificar modelos instalados
docker exec -it ollama ollama list
```

### ‚ùå Error: "Webhook not responding"
- Verifica que el workflow est√© **Active** (toggle verde)
- Verifica que n8n est√© corriendo: http://localhost:5678
- Revisa los logs de n8n:
  ```powershell
  docker logs n8n
  ```

### ‚ùå Error: "JSON parsing failed"
- Ollama a veces genera texto adicional antes del JSON
- El nodo "Code" tiene fallback para estos casos
- Intenta ajustar el prompt para ser m√°s espec√≠fico

---

## üìä Monitoreo de Workflows

### Ver Ejecuciones en n8n:
1. Click en "Executions" (panel izquierdo)
2. Ver√°s todas las ejecuciones con estado (success/error)
3. Click en una ejecuci√≥n para ver detalles y debug

### Logs del Sistema:
```powershell
# Logs de n8n
docker logs -f n8n

# Logs de Ollama
docker logs -f ollama

# Logs del backend NestJS
# Desde la carpeta del proyecto
npm run start:dev
```

---

## üéì Tips para Mejores Resultados

1. **Prompts Espec√≠ficos**: Mientras m√°s detallado el contexto, mejor el contenido generado
2. **Temperatura del Modelo**: Puedes ajustar en Ollama para m√°s creatividad vs precisi√≥n
3. **Validaci√≥n**: El backend tiene fallback si la IA falla
4. **Cach√©**: n8n guarda ejecuciones - √∫til para debugging

---

## üìö Pr√≥ximos Pasos

Una vez configurados los workflows:

1. ‚úÖ Probar generaci√≥n de contenido desde Swagger: http://localhost:3000/api
2. ‚úÖ Crear una actividad con `POST /activity`
3. ‚úÖ Generar contenido con `POST /ai/generate-content/:activityId`
4. ‚úÖ Verificar que se crearon flashcards, juegos y quiz
5. ‚úÖ Consultar contenido espec√≠fico:
   - `GET /flashcard/activity/:activityId`
   - `GET /cards-memory/activity/:activityId`
   - `GET /play-relation/activity/:activityId`
   - `GET /quiz/activity/:activityId`

---

## üÜò Ayuda

Si tienes problemas:
1. Verifica que los 3 contenedores Docker est√©n corriendo
2. Revisa los logs de cada servicio
3. Usa el modo fallback del backend (funciona sin IA)
4. Consulta la documentaci√≥n de n8n: https://docs.n8n.io
5. Consulta la documentaci√≥n de Ollama: https://ollama.ai/docs

¬°Buena suerte con tu hackathon! üöÄ
